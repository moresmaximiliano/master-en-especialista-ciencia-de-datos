{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d12d65-c95b-4ff5-a2dd-1aa27d8b2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17fb0bd3-237a-4da8-ba3e-5f5523c89fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Filas y Columnas: (44, 5)\n",
      "------------------------------------------------------------------------------------------\n",
      " Tipo de dato de columnas: y            float64\n",
      "k            float64\n",
      "l (iel)      float64\n",
      "l2 (sipa)    float64\n",
      "l3 (eph)     float64\n",
      "dtype: object\n",
      "------------------------------------------------------------------------------------------\n",
      "                   y              k     l (iel)     l2 (sipa)   l3 (eph)\n",
      "count      44.000000      44.000000   44.000000     44.000000  44.000000\n",
      "mean   703105.647971  137740.087578  132.968907  12164.156818   0.422944\n",
      "std     41577.518555   17723.796203    2.708524    506.895000   0.019874\n",
      "min    609379.989465   76231.157865  127.613600  11229.400000   0.334000\n",
      "25%    678404.737567  129656.937284  131.124925  11879.900000   0.416750\n",
      "50%    700751.309221  140613.419993  134.076550  12103.850000   0.422707\n",
      "75%    723974.386012  148319.673638  134.910975  12317.650000   0.430000\n",
      "max    791235.965542  163420.855068  136.849300  13377.400000   0.458000\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>l (iel)</th>\n",
       "      <th>l2 (sipa)</th>\n",
       "      <th>l3 (eph)</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133273.112926</td>\n",
       "      <td>133.8556</td>\n",
       "      <td>11229.4</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>677085.529173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150469.415305</td>\n",
       "      <td>134.4043</td>\n",
       "      <td>11358.8</td>\n",
       "      <td>0.431000</td>\n",
       "      <td>776486.602799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152737.114105</td>\n",
       "      <td>134.9382</td>\n",
       "      <td>11519.7</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>721458.944216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147746.629603</td>\n",
       "      <td>134.9019</td>\n",
       "      <td>11608.3</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>706597.345023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131370.536310</td>\n",
       "      <td>134.5400</td>\n",
       "      <td>11546.3</td>\n",
       "      <td>0.418000</td>\n",
       "      <td>671066.046635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>141073.189430</td>\n",
       "      <td>134.3656</td>\n",
       "      <td>11669.7</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>760576.868348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>140281.453589</td>\n",
       "      <td>134.4339</td>\n",
       "      <td>11722.8</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>690879.798252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132033.409489</td>\n",
       "      <td>134.5990</td>\n",
       "      <td>11730.9</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>686701.470619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128790.253313</td>\n",
       "      <td>134.4130</td>\n",
       "      <td>11796.9</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>672749.811392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>143522.138762</td>\n",
       "      <td>135.1065</td>\n",
       "      <td>11922.7</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>791235.965542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>149008.186931</td>\n",
       "      <td>135.3335</td>\n",
       "      <td>11996.5</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>718281.265450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>142300.301910</td>\n",
       "      <td>135.2823</td>\n",
       "      <td>11963.5</td>\n",
       "      <td>0.424110</td>\n",
       "      <td>703681.544169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>124425.518412</td>\n",
       "      <td>134.5397</td>\n",
       "      <td>11956.5</td>\n",
       "      <td>0.422414</td>\n",
       "      <td>677652.089116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>134589.437955</td>\n",
       "      <td>134.3015</td>\n",
       "      <td>11985.3</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>760703.280152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>137185.495078</td>\n",
       "      <td>134.5500</td>\n",
       "      <td>12011.9</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>694382.475776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>134851.770495</td>\n",
       "      <td>135.1205</td>\n",
       "      <td>12051.1</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>693173.549347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>131486.245995</td>\n",
       "      <td>135.4021</td>\n",
       "      <td>12099.5</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>681444.766110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>147917.725134</td>\n",
       "      <td>135.9397</td>\n",
       "      <td>12169.4</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>778401.676449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>160592.396909</td>\n",
       "      <td>136.8493</td>\n",
       "      <td>12265.1</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>721120.426853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>162113.689779</td>\n",
       "      <td>136.8370</td>\n",
       "      <td>12337.6</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>724592.921639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>152300.604211</td>\n",
       "      <td>136.1830</td>\n",
       "      <td>12342.9</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>707324.268057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>151659.167925</td>\n",
       "      <td>135.2049</td>\n",
       "      <td>12311.0</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>747428.299955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>142066.415247</td>\n",
       "      <td>134.1260</td>\n",
       "      <td>12219.9</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>696101.583522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>121488.746169</td>\n",
       "      <td>133.6061</td>\n",
       "      <td>12129.6</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>678655.620384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>114187.826004</td>\n",
       "      <td>132.5086</td>\n",
       "      <td>12132.7</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>665848.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>123592.227802</td>\n",
       "      <td>131.7059</td>\n",
       "      <td>12132.5</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>751784.460777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>127742.498080</td>\n",
       "      <td>130.5988</td>\n",
       "      <td>12146.1</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>683900.898553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>111464.939824</td>\n",
       "      <td>129.8742</td>\n",
       "      <td>12112.1</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>671361.139722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>93438.798850</td>\n",
       "      <td>128.2770</td>\n",
       "      <td>12026.6</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>632389.353535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>76231.157865</td>\n",
       "      <td>127.8285</td>\n",
       "      <td>11788.6</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>609379.989465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>116052.699105</td>\n",
       "      <td>127.6136</td>\n",
       "      <td>11870.0</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>614192.478404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>128941.850898</td>\n",
       "      <td>127.9743</td>\n",
       "      <td>11883.2</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>642403.323198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>129895.299413</td>\n",
       "      <td>127.8750</td>\n",
       "      <td>12004.2</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>654121.632889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>135907.886046</td>\n",
       "      <td>128.0771</td>\n",
       "      <td>12108.2</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>723768.207469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>140945.386396</td>\n",
       "      <td>129.0589</td>\n",
       "      <td>12264.0</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>687658.662038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>148087.290588</td>\n",
       "      <td>129.8944</td>\n",
       "      <td>12423.3</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>700591.666649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>144254.446041</td>\n",
       "      <td>130.6387</td>\n",
       "      <td>12553.8</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>691851.097368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>162032.416196</td>\n",
       "      <td>131.2870</td>\n",
       "      <td>12730.2</td>\n",
       "      <td>0.446000</td>\n",
       "      <td>773159.644658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>161813.189844</td>\n",
       "      <td>132.0477</td>\n",
       "      <td>12898.7</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>727030.130254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>148090.169206</td>\n",
       "      <td>132.6562</td>\n",
       "      <td>13051.3</td>\n",
       "      <td>0.446000</td>\n",
       "      <td>711199.437299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>143815.736426</td>\n",
       "      <td>133.3011</td>\n",
       "      <td>13148.3</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>701719.991311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>159383.727622</td>\n",
       "      <td>134.0271</td>\n",
       "      <td>13281.6</td>\n",
       "      <td>0.446000</td>\n",
       "      <td>734206.633265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>163420.855068</td>\n",
       "      <td>133.8470</td>\n",
       "      <td>13377.4</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>721387.947818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>137982.497197</td>\n",
       "      <td>132.7072</td>\n",
       "      <td>13344.8</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>700910.951793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                k   l (iel)  l2 (sipa)  l3 (eph)              y\n",
       "0   133273.112926  133.8556    11229.4  0.422000  677085.529173\n",
       "1   150469.415305  134.4043    11358.8  0.431000  776486.602799\n",
       "2   152737.114105  134.9382    11519.7  0.429000  721458.944216\n",
       "3   147746.629603  134.9019    11608.3  0.427000  706597.345023\n",
       "4   131370.536310  134.5400    11546.3  0.418000  671066.046635\n",
       "5   141073.189430  134.3656    11669.7  0.414000  760576.868348\n",
       "6   140281.453589  134.4339    11722.8  0.413000  690879.798252\n",
       "7   132033.409489  134.5990    11730.9  0.421000  686701.470619\n",
       "8   128790.253313  134.4130    11796.9  0.414000  672749.811392\n",
       "9   143522.138762  135.1065    11922.7  0.415000  791235.965542\n",
       "10  149008.186931  135.3335    11996.5  0.422000  718281.265450\n",
       "11  142300.301910  135.2823    11963.5  0.424110  703681.544169\n",
       "12  124425.518412  134.5397    11956.5  0.422414  677652.089116\n",
       "13  134589.437955  134.3015    11985.3  0.417000  760703.280152\n",
       "14  137185.495078  134.5500    12011.9  0.421000  694382.475776\n",
       "15  134851.770495  135.1205    12051.1  0.419000  693173.549347\n",
       "16  131486.245995  135.4021    12099.5  0.413000  681444.766110\n",
       "17  147917.725134  135.9397    12169.4  0.415000  778401.676449\n",
       "18  160592.396909  136.8493    12265.1  0.424000  721120.426853\n",
       "19  162113.689779  136.8370    12337.6  0.430000  724592.921639\n",
       "20  152300.604211  136.1830    12342.9  0.424000  707324.268057\n",
       "21  151659.167925  135.2049    12311.0  0.419000  747428.299955\n",
       "22  142066.415247  134.1260    12219.9  0.425000  696101.583522\n",
       "23  121488.746169  133.6061    12129.6  0.422000  678655.620384\n",
       "24  114187.826004  132.5086    12132.7  0.423000  665848.715300\n",
       "25  123592.227802  131.7059    12132.5  0.426000  751784.460777\n",
       "26  127742.498080  130.5988    12146.1  0.426000  683900.898553\n",
       "27  111464.939824  129.8742    12112.1  0.430000  671361.139722\n",
       "28   93438.798850  128.2770    12026.6  0.422000  632389.353535\n",
       "29   76231.157865  127.8285    11788.6  0.334000  609379.989465\n",
       "30  116052.699105  127.6136    11870.0  0.374000  614192.478404\n",
       "31  128941.850898  127.9743    11883.2  0.401000  642403.323198\n",
       "32  129895.299413  127.8750    12004.2  0.416000  654121.632889\n",
       "33  135907.886046  128.0771    12108.2  0.415000  723768.207469\n",
       "34  140945.386396  129.0589    12264.0  0.429000  687658.662038\n",
       "35  148087.290588  129.8944    12423.3  0.436000  700591.666649\n",
       "36  144254.446041  130.6387    12553.8  0.433000  691851.097368\n",
       "37  162032.416196  131.2870    12730.2  0.446000  773159.644658\n",
       "38  161813.189844  132.0477    12898.7  0.442000  727030.130254\n",
       "39  148090.169206  132.6562    13051.3  0.446000  711199.437299\n",
       "40  143815.736426  133.3011    13148.3  0.450000  701719.991311\n",
       "41  159383.727622  134.0271    13281.6  0.446000  734206.633265\n",
       "42  163420.855068  133.8470    13377.4  0.455000  721387.947818\n",
       "43  137982.497197  132.7072    13344.8  0.458000  700910.951793"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos un df desde un archivo de Excel\n",
    "import pandas as pd\n",
    "workbook = pd.ExcelFile('pbi max.xlsx') # tiene que estar en misma carpeta\n",
    "d = {}\n",
    "for Hoja1 in workbook.sheet_names:\n",
    "    df = workbook.parse(Hoja1) # ponemos index columna nulo xq ya tiene numerado el excel (en este caso no)\n",
    "print(f\" Filas y Columnas: {df.shape}\")\n",
    "print(\"------------------------------------------------------------------------------------------\")\n",
    "print(f\" Tipo de dato de columnas: {df.dtypes}\")\n",
    "print(\"------------------------------------------------------------------------------------------\")\n",
    "print(df.describe())\n",
    "print(\"------------------------------------------------------------------------------------------\")\n",
    "X = df[['k','l (iel)','l2 (sipa)','l3 (eph)']] # (df[:,0:4]) pongo el num de las características que tengo\n",
    "Y = df['y'] # (df[:,4]) pongo el num de características que tengo\n",
    "# Obtener el nombre de la primera columna\n",
    "first_col = df.columns[0]\n",
    "# Reordenar las columnas, excluyendo la primera y añadiéndola al final (pongo la clase al final)\n",
    "df = df[[col for col in df.columns if col != first_col] + [first_col]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5dffdc-d9fb-4cec-8f1c-70b68d18a0eb",
   "metadata": {},
   "source": [
    "# UNIDAD 4 (Feature Selection y Feature Importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce65d3-b629-44b5-856e-20cb02696144",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba85a465-c29c-44fe-acc9-ff97afd578f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>k</th>\n",
       "      <th>l (iel)</th>\n",
       "      <th>l2 (sipa)</th>\n",
       "      <th>l3 (eph)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697913</td>\n",
       "      <td>0.526315</td>\n",
       "      <td>0.179083</td>\n",
       "      <td>0.472360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.697913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540448</td>\n",
       "      <td>0.381824</td>\n",
       "      <td>0.660424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l (iel)</th>\n",
       "      <td>0.526315</td>\n",
       "      <td>0.540448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055324</td>\n",
       "      <td>0.301933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2 (sipa)</th>\n",
       "      <td>0.179083</td>\n",
       "      <td>0.381824</td>\n",
       "      <td>-0.055324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l3 (eph)</th>\n",
       "      <td>0.472360</td>\n",
       "      <td>0.660424</td>\n",
       "      <td>0.301933</td>\n",
       "      <td>0.583777</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  y         k   l (iel)  l2 (sipa)  l3 (eph)\n",
       "y          1.000000  0.697913  0.526315   0.179083  0.472360\n",
       "k          0.697913  1.000000  0.540448   0.381824  0.660424\n",
       "l (iel)    0.526315  0.540448  1.000000  -0.055324  0.301933\n",
       "l2 (sipa)  0.179083  0.381824 -0.055324   1.000000  0.583777\n",
       "l3 (eph)   0.472360  0.660424  0.301933   0.583777  1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usamos la Correlación de Pearson\n",
    "\n",
    "# Buscar buenas correlaciones de las características con la clase y descartar aquellas características con muchas correlaciones con otras características (queremos características independientes entre sí)\n",
    "# Si entre 2 características hay alta correlación, procuro mantener aquella con correlación mayor respecto a la clase o menor con respecto a demás características\n",
    "df.corr()\n",
    "\n",
    "# Vemos buenas correlaciones de 'k','l' y 'l3' con respecto a 'y' (nuestra variable a predecir)\n",
    "# Vemos también una correlación alta entre 'k' y 'l3', y medianamente altas  entre 'l' y 'k' y entre 'l3' y 'l2' (características entre si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "509e56dc-5600-4d46-a52e-bbc66e6102c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>0.671354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.001771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l (iel)</th>\n",
       "      <td>0.186016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2 (sipa)</th>\n",
       "      <td>0.596907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l3 (eph)</th>\n",
       "      <td>0.620316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p-value\n",
       "const      0.671354\n",
       "k          0.001771\n",
       "l (iel)    0.186016\n",
       "l2 (sipa)  0.596907\n",
       "l3 (eph)   0.620316"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos con la Eliminación Backward\n",
    "\n",
    "# Agregar columna de unos constante, obligatoria para el modelo sm.OLS\n",
    "X_1 = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X_1).fit() # usamos la clase (y) junto con las características en conjunto con la columna de 1 (X_1) para entrenar el modelo\n",
    "# model.pvalues  # vemos los p-values de las características\n",
    "pvalues_df = pd.DataFrame(model.pvalues, columns=['p-value']) # creamos un df con los p-valores de las características\n",
    "feature_names = ['const'] + ['k','l (iel)','l2 (sipa)','l3 (eph)'] # todas menos la clase \n",
    "pvalues_df.index = feature_names # agrego los nombres de las características a las filas\n",
    "pvalues_df\n",
    "\n",
    "# Vemos que la única variable menor a 0.05 es 'k', mientras que las otras son candidatas a ser eliminadas ('l' la más cercana al 0.05)\n",
    "# Por lo que el modelo considera que la variable que le brinda mayor explicación de 'y' es 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "870b520d-35e8-4371-82e0-1ad4b33067fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k', 'l (iel)', 'l2 (sipa)', 'l3 (eph)']\n",
      "[39.884 16.092  1.392 12.063]\n",
      "[[1.333e+05 1.339e+02 1.123e+04 4.220e-01]\n",
      " [1.505e+05 1.344e+02 1.136e+04 4.310e-01]\n",
      " [1.527e+05 1.349e+02 1.152e+04 4.290e-01]\n",
      " [1.477e+05 1.349e+02 1.161e+04 4.270e-01]\n",
      " [1.314e+05 1.345e+02 1.155e+04 4.180e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Probamos con la Selección Univariable\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression # chi2 para clasificación\n",
    "# extracción de características\n",
    "test = SelectKBest(score_func=f_regression,k=4) # k son las variables con las que me voy a quedar (si veo que hay más características con puntajes cercanos puedo ampliar)\n",
    "fit = test.fit(X,Y)\n",
    "# mostrar puntuaciones\n",
    "np.set_printoptions(precision=3)\n",
    "print(list(X.columns))\n",
    "print(fit.scores_) # imprimo las puntuaciones de todas las características\n",
    "features = fit.transform(X) # me guardo las 4 mejores características ()\n",
    "# mostrar características seleccionadas\n",
    "print(features [0:5,:])\n",
    "\n",
    "# Selecciono características sobre el puntaje del segundo array \n",
    "# El último print me muestra las 5 primeras filas de las 4 mejores características seleccionadas \n",
    "\n",
    "# Vemos que en términos de explicación, 'k' parece ser la más relevante, seguida de 'l', luego 'l3' y por último 'l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2006ed89-85b5-4e40-807d-4639f9dc7d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k', 'l (iel)', 'l2 (sipa)', 'l3 (eph)']\n",
      "Num Features: 3\n",
      "Selected Features: [False  True  True  True]\n",
      "Features Ranking: [2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Probamos la Eliminación Recursiva de Características\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# extracción de características\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=3) # \"n_features_to_select\" para indicar el número de características a obtener\n",
    "fit = rfe.fit(X,Y)\n",
    "print(list(X.columns)) # todas las características\n",
    "print(f\"Num Features: {fit.n_features_to_select}\") # número de características\n",
    "print(f\"Selected Features: {fit.support_}\") # características seleccionadas (seleccionadas como True)\n",
    "print(f\"Features Ranking: {fit.ranking_}\") # ranking de características\n",
    "# RFE comprueba también la combinación de atributos para elaborar su ranking (a diferencia de selección univariable que solo analiza con respecto a la clase)\n",
    "\n",
    "# Si le pido que me elija 2 características, me elige 'l' y 'l3' para explicar a 'y', y si le pido 3 me agrega a 'l2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b61566-0ab8-449d-a1a2-1da47dd939b0",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ede73e6e-c1ce-4e21-a715-8f03280e6006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:  4\n",
      "Variables utilizadas:  [0 1 2 3]\n",
      "Training:  0.89\n",
      "Test:  -0.09\n",
      "k\n"
     ]
    }
   ],
   "source": [
    "# Probamos Decision Trees\n",
    "\n",
    "# Busca combinaciones de características que puedan brindar un mayor grado de explicación de los datos de entrenamiento (que sirven luego para predecir sobre los datos de validación)\n",
    "from sklearn.tree import DecisionTreeRegressor # para ver características más importantes (si es problema de Clasificación \"DecisionTreeClassifier\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Genera la partición\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=7) # partición de 80/20\n",
    "# Como según el valor de random_state cambia la forma en que se dividen los datos, puedo tomar un array del [0-9] del mismo y hacer un promedio del rendimiento del modelo con datos de prueba y validación\n",
    "# Aprende el modelo\n",
    "depth = 3 # profundidad de 3 (con produndidad de 2 tenemos algo de Underfitting y mayor predicción de datos de validación, con 3 muy poco Overfitting)\n",
    "tree = DecisionTreeRegressor(criterion='squared_error', max_depth=depth) # criterio del arbol: MSE \n",
    "tree.fit(X_train,Y_train) # entreno al modelo\n",
    "# Extrae los índices de las variables utilizadas\n",
    "subset = np.unique(tree.tree_.feature[tree.tree_.feature >= 0]) # me muestra las características que utilizó el arbol\n",
    "print(\"Variables: \", X.shape[1]) # me imprime la cantidad de variables o características (filas=0,columnas=1)\n",
    "print(\"Variables utilizadas: \", subset) # me aclara cuáles variables han obtenido mejor resultado (corroborar en df)\n",
    "print(\"Training: \", tree.score(X_train,Y_train).round(2)) # efectividad del modelo para con los datos de prueba\n",
    "print(\"Test: \", tree.score(X_test,Y_test).round(2)) # efectividad del modelo para con los datos de validación\n",
    "print(df.columns[0],df.columns[1],df.columns[2],df.columns[3]) # vemos las características con que llegó al resultado\n",
    "# Entre ambos coeficientes podemos ver si se produce Overfitting (si la predicción con los datos de prueba es mucho más efectiva que con los de validación)\n",
    "# o Underfitting (si la predicción con los datos de prueba es baja o con los de validación es mucho más alto).\n",
    "# Lo ideal es que los 2 sean similares, pudiendo cambiar la profundidad para lograrlo (si la bajo se ajusta menos al entrenamiento y reduzco Overfitting y si la subo se ajusta más al entrenamient y reduzco Underfitting)\n",
    "# En cada ejecución también cambian los resultados y parámetros usados\n",
    "\n",
    "# En este caso, con la profundidad=3 (mayor correspondencia con Test) me utiliza las 4 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06fc42cf-4046-493a-a08d-36d476b26dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 0\n",
      "Variables:  4\n",
      "Variables utilizadas:  [0 1 3]\n",
      "Training:  0.87\n",
      "Test:  0.6\n",
      "\n",
      "Random state: 1\n",
      "Variables:  4\n",
      "Variables utilizadas:  [0 1 2 3]\n",
      "Training:  0.81\n",
      "Test:  0.86\n",
      "\n",
      "Random state: 2\n",
      "Variables:  4\n",
      "Variables utilizadas:  [0 1 3]\n",
      "Training:  0.81\n",
      "Test:  0.33\n",
      "\n",
      "Random state: 3\n",
      "Variables:  4\n",
      "Variables utilizadas:  [0 1 3]\n",
      "Training:  0.9\n",
      "Test:  0.26\n",
      "\n",
      "Random state: 4\n",
      "Variables:  4\n",
      "Variables utilizadas:  [0 3]\n",
      "Training:  0.81\n",
      "Test:  0.06\n",
      "\n",
      "Random state: 5\n",
      "Variables:  4\n",
      "Variables utilizadas:  [0 1 3]\n",
      "Training:  0.91\n",
      "Test:  0.13\n",
      "\n",
      "Random state: 6\n",
      "Variables:  4\n",
      "Variables utilizadas:  [0 1 2 3]\n",
      "Training:  0.83\n",
      "Test:  -0.07\n",
      "\n",
      "Random state: 7\n",
      "Variables:  4\n",
      "Variables utilizadas:  [0 1 2 3]\n",
      "Training:  0.89\n",
      "Test:  -0.09\n",
      "\n",
      "Random state: 8\n",
      "Variables:  4\n",
      "Variables utilizadas:  [0 1 2 3]\n",
      "Training:  0.86\n",
      "Test:  0.62\n",
      "\n",
      "Random state: 9\n",
      "Variables:  4\n",
      "Variables utilizadas:  [0 1 2 3]\n",
      "Training:  0.84\n",
      "Test:  -0.08\n",
      "\n",
      "Promedio Training:  0.85\n",
      "Promedio Test:  0.26\n"
     ]
    }
   ],
   "source": [
    "# Si buscamos obtener un valor más obejtivo del rendimiento del modelo y medir la sensibilidad de la partición de los datos en train/test, \n",
    "# podemos hacer un promedio de los rendimientos obtenidos cambiando el valor de random_state en la partición\n",
    "# También podemos tomar las características que más se repiten en los mejores resultados con respecto al test\n",
    "from sklearn.tree import DecisionTreeRegressor # si es problema de Regresión \"DecisionTreeRegressor\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Suponiendo que X y Y están definidos\n",
    "random_states = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # puedes usar más valores para una mejor estimación\n",
    "depth = 3\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for state in random_states:\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=state)\n",
    "    tree = DecisionTreeRegressor(criterion='squared_error', max_depth=depth)\n",
    "    tree.fit(X_train, Y_train)\n",
    "    \n",
    "    train_score = tree.score(X_train, Y_train)\n",
    "    test_score = tree.score(X_test, Y_test)\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    print(f\"Random state: {state}\")\n",
    "    print(\"Variables: \", X.shape[1])\n",
    "    print(\"Variables utilizadas: \", np.unique(tree.tree_.feature[tree.tree_.feature >= 0]))\n",
    "    print(\"Training: \", train_score.round(2))\n",
    "    print(\"Test: \", test_score.round(2))\n",
    "    print()\n",
    "\n",
    "# Promedios de las métricas\n",
    "avg_train_score = np.mean(train_scores)\n",
    "avg_test_score = np.mean(test_scores)\n",
    "\n",
    "print(\"Promedio Training: \", avg_train_score.round(2))\n",
    "print(\"Promedio Test: \", avg_test_score.round(2))\n",
    "\n",
    "# Las variables más utilizadas fueron [0,1,3], mientras que también podemos observar que el conjunto de datos es muy sensible a la aleatoriedad, ya que al cambiar la semilla los resultados del Test varían drásticamente\n",
    "# La sensibilidad ante el random_state probablemente lo produzca la poca cantidad de datos de la que disponemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e185b638-a00f-4c59-9c65-4ef65828f25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k', 'l (iel)', 'l2 (sipa)', 'l3 (eph)']\n",
      "[0.416 0.251 0.111 0.223]\n"
     ]
    }
   ],
   "source": [
    "# Probamos Extra Trees\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor # si es problema de Regresión \"ExtraTreesRegressor\"\n",
    "# extracción de características\n",
    "model = ExtraTreesRegressor() # podemos aclarar número de árboles y profundidad con \"max_depth=\", pero si lo dejamos sin identificar el algoritmo determina la profundidad hasta el punto que no comience a generar Overfitting\n",
    "model.fit(X,Y)\n",
    "print(list(X.columns)) # características del df (ignorar clase)\n",
    "print(model.feature_importances_) # importancia de cada característica para la predicción del modelo (plas,age,mass)\n",
    "# podemos poner model. y ver las statement que tiene para obtener información de como procedió para asignarle importancia a las características (base_estimator_,classes_,criterion,max_depth,max_leaf_nodes(num nodos),n_estimators(num árboles))\n",
    "# Extra Trees construye varios árboles de decisión de manera más automática\n",
    "\n",
    "# Podemos ver que en terminos de importancia, me organiza a las variables de la siguiente manera: 'k','l','l3','l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79d24b9d-ddc7-4db6-a875-a539d58d9ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (con todas las variables): 1120846444.1499803\n",
      "R² (con todas las variables): 0.552680985668655\n",
      "Importancia de las características:\n",
      "k: 0.593561263514177\n",
      "l (iel): 0.11680468357439046\n",
      "l2 (sipa): 0.10121334179899814\n",
      "l3 (eph): 0.18842071111243422\n"
     ]
    }
   ],
   "source": [
    "# Probamos el Extra Trees\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Genera la partición\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Entrenamos al algoritmo con todas las características\n",
    "forest = RandomForestRegressor(n_estimators=100) # número de árboles (100)\n",
    "forest.fit(X_train, Y_train) # entreno el 'bosque' de árboles\n",
    "\n",
    "# Extrae las importancias\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "# Predicción\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (con todas las variables): {mse}\")\n",
    "print(f\"R² (con todas las variables): {r2}\")\n",
    "\n",
    "# Mostrar importancia de características\n",
    "print(\"Importancia de las características:\")\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"{col}: {importances[i]}\")\n",
    "\n",
    "# La importancia asignada a las características por Extra Trees es la siguiente: 'k','l3','l','l2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da4da9e7-6653-4e66-ad23-e685427c4761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características ordenadas por importancia (de menor a mayor):\n",
      "Index(['k', 'l3 (eph)', 'l (iel)', 'l2 (sipa)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Extraigo los índices ordenados de mayor a menor importancia de características\n",
    "ranking = np.argsort(importances)[::-1] \n",
    "print(\"Características ordenadas por importancia (de menor a mayor):\") # me muestra el ranking de características\n",
    "print(X.columns[ranking])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b191f6a3-8f17-4cf9-996e-49228684da2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características ordenadas por importancia:\n",
      "k: 0.5936\n",
      "l3 (eph): 0.1884\n",
      "l (iel): 0.1168\n",
      "l2 (sipa): 0.1012\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imprime los nombres de las características ordenadas por importancia\n",
    "feature_names = X.columns if isinstance(X, pd.DataFrame) else X.feature_names\n",
    "print(\"Características ordenadas por importancia:\")\n",
    "for idx in ranking:\n",
    "    print(f\"{feature_names[idx]}: {importances[idx]:.4f}\")\n",
    "# Visualizo los índices de importancia de las característcas ordenados de menor a mayor en un gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Ranking de Importancias\")\n",
    "plt.barh(range(len(ranking)), importances[ranking], align='center')\n",
    "feature_names = ['k','l (iel)','l2 (sipa)','l3 (eph)'] # volvemos a declarar feature_names por haberlo transformado antes en Eliminación Backward\n",
    "plt.yticks(range(len(ranking)), [feature_names[i] for i in ranking], fontsize=9)\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Características\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "# Podemos delimitar hasta el punto que consideremos importantes a características "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65f76cd0-9ec0-402b-8e2b-6a1ea89dec88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (con todas menos las peores 2 variables): 1269385881.771606\n",
      "R² (con todas menos las peores 2 variables): 0.493400327579377\n"
     ]
    }
   ],
   "source": [
    "# Produzcamos predicciones sin tomar las 2 y 3 peores características según el Random Forest\n",
    "selected_features = ranking [:-3] # tomo todo menos las últimas 2/3 características\n",
    "# ranking [-5:] para las peores 5 características, ranking [:5] para las mejores 5 características, etc\n",
    "forest.fit(X_train.iloc[:, selected_features], Y_train)\n",
    "Y_pred_selected = forest.predict(X_test.iloc[:, selected_features]) # tampoco para el testeo tomamos el resto de características\n",
    "# Evaluación del modelo\n",
    "mse = mean_squared_error(Y_test, Y_pred_selected)\n",
    "r2 = r2_score(Y_test, Y_pred_selected)\n",
    "print(f\"Mean Squared Error (con todas menos las peores 2 variables): {mse}\")\n",
    "print(f\"R² (con todas menos las peores 2 variables): {r2}\")\n",
    "# Ver hasta que punto estoy dispuesto a perder precisión en el modelo por eliminar características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dea1410a-321e-486e-9dab-12fc040f0ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor alpha usando LassoCV: 502611.36687583645\n",
      "Mejor score usando LassoCV: 0.4953113262609944\n",
      "           Coefficient\n",
      "k             1.701338\n",
      "l (iel)       0.000000\n",
      "l2 (sipa)    -6.023268\n",
      "l3 (eph)      0.000000\n",
      "Lasso eligió 2 variables y eliminó las otras 2 variables\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Importancia de características usando modelo de Lasso')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Probamos con Lasso\n",
    "\n",
    "# Lasso es un tipo de regresión lineal (para problemas de regresión) que aplica penalizaciones a características\n",
    "from sklearn.linear_model import LassoCV\n",
    "# Importancia de las características\n",
    "reg = LassoCV()\n",
    "reg.fit(X,Y) # hago la regresión con todos los datos\n",
    "\n",
    "print(f\"Mejor alpha usando LassoCV: {reg.alpha_}\") # el valor del hiperparámetro utilizado por Lasso\n",
    "print(f\"Mejor score usando LassoCV: {reg.score(X,Y)}\") # \n",
    "coef = pd.DataFrame(reg.coef_, df.columns[0:4], columns=['Coefficient']) # configuro el df (data,filas(index),columnas)\n",
    "print(coef) # me muestra los coeficientes que le ha dado Lasso a las características\n",
    "\n",
    "# Características elegidas y eliminadas\n",
    "print(\"Lasso eligió \" + str(sum(coef['Coefficient'] != 0)) + \" variables y eliminó las otras \" \n",
    "      +  str(sum(coef['Coefficient'] == 0)) + \" variables\") # me elige los coeficientes distintos de 0 y me descarta los iguales a 0 (NOX,CHAS,INDUS)\n",
    "\n",
    "# Mostrar coeficientes\n",
    "imp_coef = coef['Coefficient'].sort_values() # ordeno los valores del df de mayor a menor\n",
    "plt.rcParams['figure.figsize'] = (7.0,5.0)\n",
    "imp_coef.plot (kind='barh') # tipo de gráfico de barra horizontal\n",
    "plt.title(\"Importancia de características usando modelo de Lasso\")\n",
    "\n",
    "# Las características con barras nulas o casi nulas son las que aportan menos (o nula) información al modelo. Se nos descartan directamente las barras nulas\n",
    "\n",
    "# En este caso, Lasso me eligió 'k' y 'l2' como las más importantes para el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29e40c5-453f-4b8b-a16b-486b7438a914",
   "metadata": {},
   "source": [
    "# UNIDAD 5 (Fase de Modelado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "76288d40-d0b9-46f5-9288-07d1dac14821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías para problema de Regresión\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c46e695e-4bf8-4cc8-b183-99b33a50ccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Mean MSE: -949408828.7383, Std MSE: 666593671.8405\n",
      "LR: Mean R²: -0.6369, Std R²: 1.9294\n",
      "Ridge: Mean MSE: -905125855.7485, Std MSE: 629928825.8352\n",
      "Ridge: Mean R²: -0.6433, Std R²: 2.0134\n",
      "Lasso: Mean MSE: -948557208.8848, Std MSE: 665264113.0283\n",
      "Lasso: Mean R²: -0.6377, Std R²: 1.9320\n",
      "ElasticNet: Mean MSE: -904571399.9902, Std MSE: 626606527.9393\n",
      "ElasticNet: Mean R²: -0.6114, Std R²: 1.9189\n",
      "KNN: Mean MSE: -1118071719.7678, Std MSE: 769234263.6399\n",
      "KNN: Mean R²: -0.4411, Std R²: 1.0314\n",
      "Decision Tree: Mean MSE: -1252853552.0273, Std MSE: 792704194.0525\n",
      "Decision Tree: Mean R²: -2.6986, Std R²: 7.1228\n",
      "SVR: Mean MSE: -1687742977.2210, Std MSE: 1206224943.8552\n",
      "SVR: Mean R²: -0.9685, Std R²: 1.2812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparo entre todos los modelos posibles de Regresión\n",
    "\n",
    "# Comparo Algoritmos (Regresión)\n",
    "# Preparar modelos para regresión\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('Ridge', Ridge()))\n",
    "models.append(('Lasso', Lasso()))\n",
    "models.append(('ElasticNet', ElasticNet()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('Decision Tree', DecisionTreeRegressor()))\n",
    "models.append(('SVR', SVR()))\n",
    "\n",
    "# Evaluar cada modelo por turno\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'neg_mean_squared_error'  # Utilizamos MSE para evaluación en problemas de regresión\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: Mean MSE: {cv_results.mean():.4f}, Std MSE: {cv_results.std():.4f}\")\n",
    "\n",
    "# Podemos también imprimir los resultados en términos de R² para tener una idea adicional de la precisión\n",
    "    cv_results_r2 = cross_val_score(model, X, Y, cv=kfold, scoring='r2')\n",
    "    print(f\"{name}: Mean R²: {cv_results_r2.mean():.4f}, Std R²: {cv_results_r2.std():.4f}\")\n",
    "\n",
    "# Resultados en términos de MSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title('Comparación de Algoritmos de Regresión')\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('MSE') # en realidad toma en cuenta el R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ff6d914-38cc-45f7-9041-4d531d44482c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 41.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 30, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 696122.383333\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.62</td>\n",
       "      <td>28969.41</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>30377.83</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.54</td>\n",
       "      <td>31924.94</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>33326.23</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.48</td>\n",
       "      <td>34003.55</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.47</td>\n",
       "      <td>34095.03</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.47</td>\n",
       "      <td>34190.89</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>34515.58</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>34515.68</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>34515.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>34515.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>34515.78</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>34515.78</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>34515.78</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>34582.57</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>34699.35</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>35973.50</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.41</td>\n",
       "      <td>36108.04</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.41</td>\n",
       "      <td>36263.13</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>36610.08</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>36727.67</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>37063.55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>37628.12</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>37628.12</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.33</td>\n",
       "      <td>38385.99</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.31</td>\n",
       "      <td>38996.65</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>39154.56</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GammaRegressor</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>39247.32</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>44401.67</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>50262.77</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>50562.77</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>51906.77</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>51906.77</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>51906.77</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>51906.77</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>53245.68</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>-253.06</td>\n",
       "      <td>-213.97</td>\n",
       "      <td>689675.77</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>-273.94</td>\n",
       "      <td>-231.64</td>\n",
       "      <td>717458.09</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>-275.57</td>\n",
       "      <td>-233.02</td>\n",
       "      <td>719578.88</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>-275.58</td>\n",
       "      <td>-233.03</td>\n",
       "      <td>719599.40</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>-926.01</td>\n",
       "      <td>-783.40</td>\n",
       "      <td>1317411.61</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Adjusted R-Squared  R-Squared       RMSE  \\\n",
       "Model                                                                     \n",
       "ExtraTreesRegressor                          0.55       0.62   28969.41   \n",
       "RandomForestRegressor                        0.51       0.58   30377.83   \n",
       "GradientBoostingRegressor                    0.46       0.54   31924.94   \n",
       "OrthogonalMatchingPursuit                    0.41       0.50   33326.23   \n",
       "BaggingRegressor                             0.38       0.48   34003.55   \n",
       "DecisionTreeRegressor                        0.38       0.47   34095.03   \n",
       "PoissonRegressor                             0.38       0.47   34190.89   \n",
       "Lasso                                        0.36       0.46   34515.58   \n",
       "LassoLars                                    0.36       0.46   34515.68   \n",
       "OrthogonalMatchingPursuitCV                  0.36       0.46   34515.78   \n",
       "TransformedTargetRegressor                   0.36       0.46   34515.78   \n",
       "LinearRegression                             0.36       0.46   34515.78   \n",
       "LassoLarsIC                                  0.36       0.46   34515.78   \n",
       "Lars                                         0.36       0.46   34515.78   \n",
       "SGDRegressor                                 0.36       0.46   34582.57   \n",
       "Ridge                                        0.36       0.46   34699.35   \n",
       "XGBRegressor                                 0.31       0.42   35973.50   \n",
       "LassoCV                                      0.30       0.41   36108.04   \n",
       "RidgeCV                                      0.30       0.41   36263.13   \n",
       "AdaBoostRegressor                            0.28       0.39   36610.08   \n",
       "KNeighborsRegressor                          0.28       0.39   36727.67   \n",
       "ElasticNet                                   0.27       0.38   37063.55   \n",
       "LarsCV                                       0.24       0.36   37628.12   \n",
       "LassoLarsCV                                  0.24       0.36   37628.12   \n",
       "RANSACRegressor                              0.21       0.33   38385.99   \n",
       "HuberRegressor                               0.19       0.31   38996.65   \n",
       "TweedieRegressor                             0.18       0.31   39154.56   \n",
       "GammaRegressor                               0.18       0.30   39247.32   \n",
       "ExtraTreeRegressor                          -0.05       0.11   44401.67   \n",
       "ElasticNetCV                                -0.35      -0.14   50262.77   \n",
       "NuSVR                                       -0.37      -0.16   50562.77   \n",
       "BayesianRidge                               -0.44      -0.22   51906.77   \n",
       "LGBMRegressor                               -0.44      -0.22   51906.77   \n",
       "HistGradientBoostingRegressor               -0.44      -0.22   51906.77   \n",
       "DummyRegressor                              -0.44      -0.22   51906.77   \n",
       "SVR                                         -0.51      -0.28   53245.68   \n",
       "PassiveAggressiveRegressor                -253.06    -213.97  689675.77   \n",
       "KernelRidge                               -273.94    -231.64  717458.09   \n",
       "LinearSVR                                 -275.57    -233.02  719578.88   \n",
       "MLPRegressor                              -275.58    -233.03  719599.40   \n",
       "GaussianProcessRegressor                  -926.01    -783.40 1317411.61   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "ExtraTreesRegressor                  0.10  \n",
       "RandomForestRegressor                0.17  \n",
       "GradientBoostingRegressor            0.05  \n",
       "OrthogonalMatchingPursuit            0.01  \n",
       "BaggingRegressor                     0.03  \n",
       "DecisionTreeRegressor                0.02  \n",
       "PoissonRegressor                     0.01  \n",
       "Lasso                                0.01  \n",
       "LassoLars                            0.01  \n",
       "OrthogonalMatchingPursuitCV          0.02  \n",
       "TransformedTargetRegressor           0.02  \n",
       "LinearRegression                     0.01  \n",
       "LassoLarsIC                          0.01  \n",
       "Lars                                 0.01  \n",
       "SGDRegressor                         0.00  \n",
       "Ridge                                0.01  \n",
       "XGBRegressor                         0.05  \n",
       "LassoCV                              0.06  \n",
       "RidgeCV                              0.01  \n",
       "AdaBoostRegressor                    0.06  \n",
       "KNeighborsRegressor                  0.01  \n",
       "ElasticNet                           0.00  \n",
       "LarsCV                               0.01  \n",
       "LassoLarsCV                          0.01  \n",
       "RANSACRegressor                      0.02  \n",
       "HuberRegressor                       0.02  \n",
       "TweedieRegressor                     0.02  \n",
       "GammaRegressor                       0.00  \n",
       "ExtraTreeRegressor                   0.02  \n",
       "ElasticNetCV                         0.06  \n",
       "NuSVR                                0.00  \n",
       "BayesianRidge                        0.00  \n",
       "LGBMRegressor                        0.01  \n",
       "HistGradientBoostingRegressor        0.03  \n",
       "DummyRegressor                       0.01  \n",
       "SVR                                  0.02  \n",
       "PassiveAggressiveRegressor           0.01  \n",
       "KernelRidge                          0.01  \n",
       "LinearSVR                            0.01  \n",
       "MLPRegressor                         0.07  \n",
       "GaussianProcessRegressor             0.02  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Otra opción para encontrar el modelo indicado es probar todos los modelos sin configuración de hiperparámetros de la siguiente manera\n",
    "# En este caso se efectúa el entrenamiento por división en train/test\n",
    "\n",
    "# Me recomienda los mejores modelos base (sin configuración de hiperparámetros) para nuestro set de datos\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Regression problem\n",
    "import pandas as pd\n",
    "workbook = pd.ExcelFile('pbi max.xlsx') # tiene que estar en misma carpeta\n",
    "d = {}\n",
    "for Hoja1 in workbook.sheet_names:\n",
    "    df = workbook.parse(Hoja1)\n",
    "X = df[['k','l3 (eph)']] # (df[:,0:4])\n",
    "Y = df['y'] # (df[:,4])\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=.3,random_state =7) \n",
    "reg = LazyRegressor(verbose=0,ignore_warnings=True, custom_metric=None ) # Ver lo de custom_metric\n",
    "models,predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "models\n",
    "\n",
    "# Aca podemos ver que no tengo modelos recomendados con tanto nivel de predicción, esto en parte se debe a que todavía no efectúe la eliminación de características\n",
    "# Podemos comprobar configurando de manera diferente X (cambiando las características a usar) el nivel de predicción que puedo conseguir\n",
    "# Puedo probar también variando el nivel de división por train/test e incluso ponderar diferentes resultados de random_state\n",
    "# A pesar de la varianza por random_state, puedo ver que los modelos recomendados siguen siendo los mismos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865f3b4-5795-407a-9f21-40b116a9af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar algoritmos de Ensemble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
